# Semantic WEb quEry Profiler (SWEEP) Project

SWEEP (Semantic WEb quEry Profiler) is a tool that allows data providers using a TPF server (see LDF @ linkeddatafragments.org/) to manage data usage.


# Testing SWEEP

SWEEP Monitor:
http://sweep.priloo.univ-nantes.fr 

SWEEP TPF Client:
http://tpf-client-sweep.priloo.univ-nantes.fr

SWEEP TPF Server:
http://tpf-server-sweep.priloo.univ-nantes.fr


# Installing SWEEP
## Prelude

#### macOS
You need to install [Homebrew](http://brew.sh/).

and then install Python:
```bash
brew install python
```
#### Ubuntu
```
sudo apt-get install python-dev python-setuptools
```

## Dependencies
You need to install dependencies with pip:
- lxml
- RDFLib
- networkx
- SPARQLWrapper
- iso8601

SWEEP was tested withn python3.5 and Python3.6.

## Adapting TPF to SWEEP

TPF server and client on http://linkeddatafragments.org/software/ can be used to test SWEEP. But, some changes have to be done.

### TPF Server

SWEEP need the TPF Server log to process. So, changes have to be done on TPF Server code. First change concerns thne file ./bin/ldf-server. Just add the code (from 'Begin SWEEP' to 'End SWEEP') :
```nodejs
...
var configDefaults = JSON.parse(fs.readFileSync(path.join(__dirname, '../config/config-defaults.json'))),
    config = _.defaults(JSON.parse(fs.readFileSync(args[0])), configDefaults),
    port = parseInt(args[1], 10) || config.port,
    workers = parseInt(args[2], 10) || config.workers,
    constructors = {};

//------------------> Begin SWEEP <------------------------
var sweep = config.sweep || '' ;
config.sweep = sweep ;
//------------------> End SWEEP <------------------------

// Start up a cluster master
if (cluster.isMaster) {
...
```
It allows to give the SWEEP URL to the TPF Sever.

Next, install the Request' module and do next changes in ./lib/views/RdfView.js

```nodejs
...

var contentTypes = 'application/trig;q=0.9,application/n-quads;q=0.7,' +
                   'application/ld+json;q=0.8,application/json;q=0.8,' +
                   'text/turtle;q=0.6,application/n-triples;q=0.5,text/n3;q=0.6';

//------------------> Begin SWEEP <------------------------
var http = require('request');
var trace = "";
var cpt = 0;
//------------------> End SWEEP <------------------------


// Creates a new RDF view with the given name and settings
function RdfView(viewName, settings) {
  if (!(this instanceof RdfView))
...

  // Write the triples with a content-type-specific writer
  var self = this,
      writer = /json/.test(settings.contentType) ? this._createJsonLdWriter(settings, response, done)
                                                 : this._createN3Writer(settings, response, done);
  //------------------> Begin SWEEP <------------------------
  cpt += 1;
  settings.cpt =  'e'+process.pid+'-'+cpt ;
  settings.tpList = '';
  //------------------> End SWEEP <------------------------

  settings.writer = writer;

...

  function after()  {
self._renderViewExtensions('After',  settings, request, response, writer.end);

    //------------------> Begin SWEEP <------------------------
    settings.tpList = settings.tpList + '</l>';
    http({
      uri: settings.sweep+"/data",
      method: "POST",
      form: {
        data: settings.tpList,
        no : settings.cpt,
        ip : settings.sweep_ip,
        time : settings.sweep_time
      }
    }, function(error, response, body) {
       console.log('data:',body,error);
    });
    //------------------> End SWEEP <------------------------

}
  function before() {

  //------------------> Begin SWEEP <------------------------
  var ip =
     request.connection.remoteAddress ||
     request.socket.remoteAddress ||
     request.headers['x-forwarded-for'] || request.connection.socket.remoteAddress;

  now = new Date();
  settings.sweep_ip = ip
  settings.sweep_time = now.toJSON()
  trace = '<e>';
  q = settings.query.patternString;
  subject = settings.query.subject;
  predicate = settings.query.predicate;
  object = settings.query.object;
  var s= ( subject=== undefined ? '<s type="var"/>' : toIRI(subject,'s'));
  var p= ( predicate=== undefined ? '<p type="var"/>' : toIRI(predicate,'p'));
  var o= ( object=== undefined ? '<o type="var"/>' : toIRI(object,'o'));
  trace += s+p+o+'</e>';
  settings.tpList = '<l>'+trace;
  //------------------> End SWEEP <------------------------

...

    data: function (s, p, o, g) {
      writer.addTriple(s, p, o, supportsGraphs ? g : null);

      //------------------> Begin SWEEP <------------------------
      if (o === undefined)
        tp = '<d>'+toIRI(s.subject,'s')+''+toIRI(s.predicate,'p')+''+toIRI(s.object,'o')+'</d>';
        else tp = '<d>'+toIRI(s,'s')+' '+toIRI(p,'p')+' '+toIRI(o,'o')+'</d>';
      settings.tpList = settings.tpList + tp
      //------------------> End SWEEP <------------------------

    },
    // Adds the metadata triple to the output
    meta: function (s, p, o) {
      // Relate the metadata graph to the data
      if (supportsGraphs && !metadataGraph) {
        metadataGraph = settings.metadataGraph;
        writer.addTriple(metadataGraph, primaryTopic, settings.fragmentUrl, metadataGraph);
      }
      // Write the triple
      if (s && p && o && !N3.Util.isLiteral(s)) {
        writer.addTriple(s, p, o, metadataGraph);
        //------------------> Begin SWEEP <------------------------
        if (o === undefined)
          tp = '<m>'+toIRI(s.subject,'s')+''+toIRI(s.predicate,'p')+''+toIRI(s.object,'o')+'</m>';
          else tp = '<m>'+toIRI(s,'s')+' '+toIRI(p,'p')+' '+toIRI(o,'o')+'</m>';
        settings.tpList = settings.tpList + tp
        //------------------> End SWEEP <------------------------
      }
    },

...

//------------------> Begin SWEEP <------------------------
function toIRI(s,p) {return s[0]   !== '_' ? (!N3.Util.isLiteral(s) ? '<'+p+' type="iri" val="'+s.replace(/&/gi, "&amp;")+'"/>' : '<'+p+' type="lit"><![CDATA['+s+']]></'+p+'>') : '<'+p+' type="bkn" val="'+s+'"/>';}
//------------------> End SWEEP <------------------------

module.exports = RdfView;

```
These changes allows the TPF Server to send to SWEEP the execution log. These changes are enough to run SWEEP. But, to evaluate SWEEP process, we have to change the TPF Cleint.

### TPF Client

Let's take the ./bin/ldf-client file. Do next changes :
```nodejs
// Parse and initialize configuration
var configFile = args.c ? args.c : path.join(__dirname, '../config-default.json'),
    config = JSON.parse(fs.readFileSync(configFile, { encoding: 'utf8' })),
    queryFile = args.f || args.q || args._.pop(),
    startFragments = args._,
    query = args.q || (args.f || fs.existsSync(queryFile) ? fs.readFileSync(queryFile, 'utf8') : queryFile),
    mimeType = args.t || 'application/json',
    datetime = args.d || config.datetime;

//------------------> Begin SWEEP <------------------------
var sweep = args.s || '' ;
config.sweep = sweep ;
//------------------> End SWEEP <------------------------

// parse memento datetime
if (datetime)
  config.datetime = datetime === true ? new Date() : new Date(datetime);

```

Then, lfd-client command line allows ti specify the SWEEP server (with '-s').
Next, do changes on ./lib/sparql/SparqlIterator.js :
```nodejs
...
  // Transform the query into a cascade of iterators
  try {
    // Parse the query if needed
    if (typeof query === 'string') {

      //------------------> Begin SWEEP <------------------------
      if (options.sweep != ''){      
        now = new Date();
        trace = '<query time="'+now.toJSON()+'"><![CDATA['+query+']]></query>'
        http({    
          uri: options.sweep+"/query",
          method: "POST",
          form: {
            data: trace, no:'ldf-client', 'bgp_list': '<l/>'
          }
        }, function(error, response, body) {
        }); 
      }
      //------------------> End SWEEP <------------------------

      query = new SparqlParser(options.prefixes).parse(query);
    }
...
```

This code sends the query to SWEEP. This permits to SWEEP to process precision and recall.

## Running SWEEP

From `~/SWEEP` run the comand to run SWEEP:
```bash
nohup python3.5 sweep-streamWS.py -g 0.250 -to 0.2 -l 20 --port 5000 &> resSWEEP &
```

For the (modified) TPF Server, change the config file to specify the SWEEP server and datasources :

```bash
{
  "title": "My Linked Data Fragments server",
  "port": 5001,
  "workers": 8,
  "sweep" : "http://127.0.0.1:5002",
...
  "datasources": {
   "dbpedia": {
      "title": "DBpedia",
      "type": "HdtDatasource",
      "description": "DBpedia 3.8 backend",
      "settings": { "file": "dbpedia-3.8.hdt" }    
   },
   ...
  },
...
```
Then run the server :
```bash
./bin/ldf-server config/config-dbp.json
```

Finally, the SWEEP client to test SWEEP can be run :
```bash
nohup python3.5 qsim-WS.py --sweep http://127.0.0.1:5000 -s http://127.0.0.1:5001 -c /.../bin/ldf-client --port 5002 -v -g 0.25 &> resQsim-WS &
```


#### Command lines

```bash
$ python3.6 sweep-streamWS.py -h
usage: sweep-streamWS.py [-h] [-g GAP] [-to TIMEOUT] [-o] [-l NLAST]
                         [--port PORT] [--chglientMode]

Linked Data Query Profiler (for a modified TPF server)

optional arguments:
  -h, --help            show this help message and exit
  -g GAP, --gap GAP     Gap in minutes (60 by default)
  -to TIMEOUT, --timeout TIMEOUT
                        TPF server Time Out in minutes (0 by default). If '-to
                        0', the timeout is the gap.
  -o, --optimistic      BGP time is the last TP added (False by default)
  -l NLAST, --last NLAST
                        Number of last BGPs to view (10 by default)
  --port PORT           Port (5002 by default)
  --chglientMode        Do TPF Client mode
```


```bash
$ python3.6 qsim-WS.py -h
usage: qsim-WS.py [-h] [--sweep SWEEP] [-s TPFSERVER] [-c TPFCLIENT] [-v]
                  [-g GAP] [-to TIMEOUT] [--port PORT]

Linked Data Query Profiler (for a modified TPF server)

optional arguments:
  -h, --help            show this help message and exit
  --sweep SWEEP         SWEEP ('http://127.0.0.1:5002' by default)
  -s TPFSERVER, --server TPFSERVER
                        TPF Server ('http://127.0.0.1:5000' by default)
  -c TPFCLIENT, --client TPFCLIENT
                        TPF Client ('...' by default)
  -v, --valid           Do precision/recall
  -g GAP, --gap GAP     Gap in minutes (60 by default)
  -to TIMEOUT, --timeout TIMEOUT
                        TPF Client Time Out in minutes (no timeout by
                        default).
  --port PORT           Port (5002 by default)
```

